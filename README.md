# NLP-LoRA-FineTuning-Project
CEN445 Project - Fine-tuning Qwen2.5-Coder using LoRA method
Qwen2.5-Coder LoRA Fine-Tuning Project üöÄThis repository contains the implementation of a LoRA (Low-Rank Adaptation) fine-tuning project for the Qwen2.5-Coder-1.5B-Instruct model. The goal of this project is to enhance the code generation capabilities of the base model using two different dataset strategies: Deep Instruction (Chain-of-Thought) and Diverse Instruction.This project was conducted as part of the CEN445 - Introduction to Data Visualization course.üõ†Ô∏è Environment & HardwarePlatform: Google Colab ProGPU: NVIDIA A100 (40GB)Training Method: LoRA (PEFT)Precision: bfloat16 (Brain Floating Point)üìÇ Repository Structuretrain.py: The training script used for fine-tuning the model.livecodebench_eval.py: The evaluation script adapted from the LiveCodeBench benchmark.requirements.txt: List of dependencies required to run the project.deeplossfinal.png: Loss analysis graph for the Deep Instruction model.diverselossfinal.png: Loss analysis graph for the Diverse Instruction model.‚ö†Ô∏è Important Notes on Code UsageIf you plan to run these scripts, please pay attention to the following modifications:Google Drive Paths in train.py:The training script is configured to save checkpoints directly to Google Drive to prevent data loss.Python# Example in train.py
OUTPUT_DIR = "/content/drive/MyDrive/CodeGen_Project/deep_instruction/checkpoints"
Please update OUTPUT_DIR to match your local or cloud environment path.Flash Attention in livecodebench_eval.py:Although we used an A100 GPU, we encountered compatibility issues with the specific libraries in the evaluation environment. Therefore, we modified the original livecodebench_eval.py by removing the use_flash_attention_2=True arguments. The model runs in standard bfloat16 mode during evaluation.üìä Benchmark Results (Pass@1)We evaluated the models using the LiveCodeBench (AtCoder - Easy) dataset consisting of 41 coding problems.ModelBest CheckpointPass@1 ScoreProblems SolvedBase Model (Qwen2.5-Coder)-26.83%11 / 41Deep Instruction (Ours)Step-20034.15% üèÜ14 / 41Diverse InstructionStep-20029.27%12 / 41Conclusion: The Deep Instruction model significantly outperformed both the Base model (+7.3%) and the Diverse Instruction model, proving that training with Chain-of-Thought (CoT) data is highly effective for reasoning-based coding tasks.üìà Training Analysis & OverfittingWe monitored Train, Validation, and Test losses throughout the training process.1. Deep Instruction Model2. Diverse Instruction Modelüîç Technical ObservationIn both training sessions, the Validation Loss reached its minimum around Step 200. As training continued to Step 300, the validation loss began to increase (or plateau), and the benchmark performance dropped. This indicates that overfitting started occurring after Step 200. Therefore, we selected the Step 200 checkpoints as our final models.üöÄ How to RunInstall Dependencies:Bashpip install -r requirements.txt
Start Training:Bashpython train.py
Run Evaluation:Bashpython livecodebench_eval.py --model_type deep_instruction --platform atcoder --difficulty easy
üìú LicenseThis project is licensed under the Apache License 2.0.
